{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for sequence classification in the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Jr4cugH3mZ_X"
   },
   "outputs": [],
   "source": [
    "# Credits: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "Say V be the whole corpus of words in the dataset. There is a table where all the words are given a rank. \n",
    "Rank is assigned based on the frequency of that word in the corpus.\n",
    "Eg: 'The' : 1 ; 'a':2 ..... 'phone':378...etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kjf2yM5GF4_8",
    "outputId": "be416181-8cc1-46ea-e296-d5654d8082b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_words` argument in `load_data` has been renamed `num_words`.\n"
     ]
    }
   ],
   "source": [
    "#Refer: https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
    "\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000  # limiting the words upto rank 5000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYEE6ts7GAjC",
    "outputId": "fdea4115-3e42-40b7-ff17-6e25779ac4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "<class 'list'>\n",
      "189\n",
      "218\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])\n",
    "print(type(X_train[1]))\n",
    "print(len(X_train[1]))\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhWo1v1M7elZ",
    "outputId": "f5935803-1134-476e-c128-77237c706a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wn1coShH7LvP",
    "outputId": "490377a8-0359-4b14-dfbe-3da8e8148a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4998\n",
      "4987\n"
     ]
    }
   ],
   "source": [
    "print(max(numpy.max(X_test)))\n",
    "print(max(numpy.max(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: Input of LSTM is supposed to be variable length time series data. Then why to apply padding on the input vector to make all data points same length?\n",
    "A: Assume there are 3 input vectors. X1 contains 189 words, X2- 310, X3 -150. We want to back propagate each of the input, back propagate over time. What we are doing is an SGD operation with batch size =1, ie at any point of time we are processing one sequence, not combining sequences for processing. And this approach is too slow and takes lot of time. So the remedy is perform SGD with batch size = k. ie LSTM has several inputs. One input receives X11,X21,X31â€¦ (first element of every data points. So instead of processing SGD for whole inputs, the method is collecting all the first words from input vectors of batch size k as a set and sent. Similarly X12,X22,X32.. will sent simultaneously. So in order to perform based on batch we need input vector size to be same. This will speed up the training in LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57N6TyKLH-Pc",
    "outputId": "1484132a-f5e1-4729-84b8-4c74e808a402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 600)\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    1  194 1153  194    2   78  228    5    6\n",
      " 1463 4369    2  134   26    4  715    8  118 1634   14  394   20   13\n",
      "  119  954  189  102    5  207  110 3103   21   14   69  188    8   30\n",
      "   23    7    4  249  126   93    4  114    9 2300 1523    5  647    4\n",
      "  116    9   35    2    4  229    9  340 1322    4  118    9    4  130\n",
      " 4901   19    4 1002    5   89   29  952   46   37    4  455    9   45\n",
      "   43   38 1543 1905  398    4 1649   26    2    5  163   11 3215    2\n",
      "    4 1153    9  194  775    7    2    2  349 2637  148  605    2    2\n",
      "   15  123  125   68    2    2   15  349  165 4362   98    5    4  228\n",
      "    9   43    2 1157   15  299  120    5  120  174   11  220  175  136\n",
      "   50    9 4373  228    2    5    2  656  245 2350    5    4    2  131\n",
      "  152  491   18    2   32    2 1212   14    9    6  371   78   22  625\n",
      "   64 1382    9    8  168  145   23    4 1690   15   16    4 1355    5\n",
      "   28    6   52  154  462   33   89   78  285   16  145   95]\n"
     ]
    }
   ],
   "source": [
    "# truncate and/or pad input sequences\n",
    "max_review_length = 600  # Several reviews has varying length. Inorder to make a fixed sized matrix we do the padding\n",
    "# Eg: X1 has a length of 189 words. Make it 600 by adding zeroes in the beginning\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CquzlqrOIYGn",
    "outputId": "0838129c-fbde-4184-97e1-9c6105113bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 600, 32)           160000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               53200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "# The first layer of model is embedding layer. What is the need of this ? Refer que word doc\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100)) # we are defining 100 LSTMs parallely ie one behind the other geometrically. \n",
    "#32 dim input from embedding feeding to all LSTMs.and gives 100 D output\n",
    "# no. of parameters in a LSTM having 32 inputs (m) and 100 outputs (n) is 4(nm+ n square+n).n term is the bias (b). LSTM keras has bias as default\n",
    "# here no of params is 4(32 square + 32*100 + 100)= 53200\n",
    "model.add(Dense(1, activation='sigmoid')) # outputs of all LSTMs connected to a single sigmooid unit and gives y_hat (binary)\n",
    "# sigma ( WTX+b) . we have 100 weights associated with output plus a bias term. So 101 params.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "A_FT0dPNIeLP",
    "outputId": "51f9408c-891d-49b5-b0fc-720eba1ea5a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 348s 883ms/step - loss: 0.4726 - accuracy: 0.7637\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 353s 902ms/step - loss: 0.3131 - accuracy: 0.8707\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 368s 941ms/step - loss: 0.2381 - accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 358s 916ms/step - loss: 0.2196 - accuracy: 0.9155\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 361s 922ms/step - loss: 0.2152 - accuracy: 0.9182\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 363s 928ms/step - loss: 0.1843 - accuracy: 0.9290\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 360s 922ms/step - loss: 0.1535 - accuracy: 0.9437\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 366s 936ms/step - loss: 0.1416 - accuracy: 0.9474\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 373s 954ms/step - loss: 0.1151 - accuracy: 0.9607\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 371s 948ms/step - loss: 0.2057 - accuracy: 0.9155\n",
      "Accuracy: 86.05%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgVm16Yt-pef"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_IMDB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
